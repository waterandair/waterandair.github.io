<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Spark 读取和转存数据(python) | Waterandair&#39;s Blog</title>
  <meta name="keywords" content=" Spark , 开发 ">
  <meta name="description" content="Spark 读取和转存数据(python) | Waterandair&#39;s Blog">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta property="og:type" content="website">
<meta property="og:title" content="tags">
<meta property="og:url" content="https://waterandair.github.io/tags/index.html">
<meta property="og:site_name" content="Waterandair&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2019-07-17T18:58:18.000Z">
<meta property="article:modified_time" content="2019-12-28T06:03:51.541Z">
<meta property="article:author" content="Waterandair">
<meta name="twitter:card" content="summary">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.0.1" rel="stylesheet">

<link href="/css/hl_theme/darcula.css?v=1.0.1" rel="stylesheet">

<link href="//cdn.bootcss.com/animate.css/3.5.2/animate.min.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="/js/jquery.autocomplete.min.js?v=1.0.1" ></script>

<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>



<script src="/js/iconfont.js?v=1.0.1" ></script>

<meta name="generator" content="Hexo 4.2.0"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="false">
  <input class="theme_blog_path" value="">
</div>

<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/" class="avatar_target">
    <img class="avatar" src="/img/avatar.jpg" />
</a>
<div class="author">
    <span>Waterandair</span>
</div>

<div class="icon">
    
        
        <a title="rss" href="/atom.xml" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-rss"></use>
                </svg>
            
        </a>
        
    
        
        <a title="github" href="https://github.com/waterandair" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-github"></use>
                </svg>
            
        </a>
        
    
        
        <a title="email" href="mailto:156577812@qq.com" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-email"></use>
                </svg>
            
        </a>
        
    
</div>



<a class="more-menus">更多菜单</a>


<ul>
    <li><div class="all active">全部文章<small>(74)</small></div></li>
    
        
            
            <li><div data-rel="算法与数据结构"><i class="fold iconfont icon-right"></i>算法与数据结构<small>(1)</small></div>
                
                    <ul class="sub hide">
                        
                        <li><div data-rel="基础">基础<small>(1)</small></div>
                            
                        </li>
                            
                    </ul>
                
            </li>
            
        
    
        
            
            <li><div data-rel="后端开发"><i class="fold iconfont icon-right"></i>后端开发<small>(33)</small></div>
                
                    <ul class="sub hide">
                        
                        <li><div data-rel="Redis">Redis<small>(6)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="Ansible">Ansible<small>(2)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="Docker">Docker<small>(1)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="Linux">Linux<small>(4)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="MySQL">MySQL<small>(16)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="RPC">RPC<small>(4)</small></div>
                            
                        </li>
                            
                    </ul>
                
            </li>
            
        
    
        
            
            <li><div data-rel="大数据"><i class="fold iconfont icon-right"></i>大数据<small>(29)</small></div>
                
                    <ul class="sub hide">
                        
                        <li><div data-rel="Hadoop">Hadoop<small>(1)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="CDH">CDH<small>(1)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="Hive">Hive<small>(2)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="基础">基础<small>(1)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="Kafka">Kafka<small>(1)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="数据分析">数据分析<small>(2)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="Spark">Spark<small>(19)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="Zookeeper">Zookeeper<small>(2)</small></div>
                            
                        </li>
                            
                    </ul>
                
            </li>
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
            <li><div data-rel="Go"><i class="fold iconfont icon-right"></i>Go<small>(1)</small></div>
                
                    <ul class="sub hide">
                        
                        <li><div data-rel="Go 语言注意点">Go 语言注意点<small>(1)</small></div>
                            
                        </li>
                            
                    </ul>
                
            </li>
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
            <li><div data-rel="环境搭建">环境搭建<small>(5)</small></div>
                
            </li>
            
        
    
        
            
        
    
        
            
        
    
        
            
            <li><div data-rel="机器学习"><i class="fold iconfont icon-right"></i>机器学习<small>(3)</small></div>
                
                    <ul class="sub hide">
                        
                        <li><div data-rel="算法">算法<small>(2)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="案例">案例<small>(1)</small></div>
                            
                        </li>
                            
                    </ul>
                
            </li>
            
        
    
        
            
        
    
        
            
            <li><div data-rel="Interesting"><i class="fold iconfont icon-right"></i>Interesting<small>(1)</small></div>
                
                    <ul class="sub hide">
                        
                        <li><div data-rel="Music">Music<small>(1)</small></div>
                            
                        </li>
                            
                    </ul>
                
            </li>
            
        
    
        
            
        
    
        
            
        
    
        
            
            <li><div data-rel="Python">Python<small>(1)</small></div>
                
            </li>
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
    
    
    
    <a class="dynamic-menu " target="_blank"  href="https://github.com/waterandair">github</a>
    
    </div>
    <div><a class="about  site_url"  href="/about">关于</a></div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="74">
<input type="hidden" id="yelog_site_word_count" value="137.6k">
<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="back-title-list"></i>
    </div>
    <div class="friends-content">
        <ul>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <form onkeydown="if(event.keyCode==13){return false;}">
        <input class="search" type="text" placeholder="Search..." autocomplete="off"id="local-search-input" >
        <i class="cross"></i>
        <span>
            <label for="tagswitch">Tags:</label>
            <input id="tagswitch" type="checkbox" style="display: none" />
            <i id="tagsWitchIcon"></i>
        </span>
    </form>
    <div class="tags-list">
    
    <li class="article-tag-list-item">
        <a class="color1">时间复杂度</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">大O算法</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">Ansible</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color4">大数据</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color1">Redis</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color1">Nosql</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">Docker</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">Go</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">后端开发</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color1">Linux</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">Hadoop</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">Hive</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">环境搭建</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">Java</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color1">Kafka</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">消息队列</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">Zookeeper</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">机器学习</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">回归</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color1">MySQL</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">音乐</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color1">Numpy</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">Pandas</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">Python</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color1">Spark</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">开发</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color4">RPC</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">性能调优</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">原理</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color4">Spark 原理</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">工具</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">分布式协作框架</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color1">Linux 权限问题</a>
    </li>
    
    <div class="clearfix"></div>
</div>

    
    <nav id="title-list-nav">
        
        <a id="top" class="后端开发 Ansible "
           href="/2017-09-30-ansible-base-use%20copy.html"
           data-tag="Ansible"
           data-author="" >
            <span class="post-title" title="ansible 一些基本使用方法的记录">ansible 一些基本使用方法的记录</span>
            <span class="post-date" title="2017-09-30 11:20:47">2017/09/30</span>
        </a>
        
        <a id="top" class="大数据 基础 "
           href="/2017-10-06-big-data-collect.html"
           data-tag="大数据"
           data-author="" >
            <span class="post-title" title="大数据的数据采集流程">大数据的数据采集流程</span>
            <span class="post-date" title="2017-10-06 21:49:02">2017/10/06</span>
        </a>
        
        <a id="top" class="后端开发 Ansible "
           href="/2017-09-30-ansible-base-use.html"
           data-tag="Ansible"
           data-author="" >
            <span class="post-title" title="ansible 一些基本使用方法的记录">ansible 一些基本使用方法的记录</span>
            <span class="post-date" title="2017-09-30 11:20:47">2017/09/30</span>
        </a>
        
        <a id="top" class="大数据 CDH "
           href="/2017-12-15-big-data-cdh-5-14-2-install.html"
           data-tag=""
           data-author="" >
            <span class="post-title" title="centos7 本地源方式部署 CDH 大数据服务管理平台">centos7 本地源方式部署 CDH 大数据服务管理平台</span>
            <span class="post-date" title="2017-12-15 11:20:47">2017/12/15</span>
        </a>
        
        <a id="top" class="后端开发 Docker "
           href="/2017-10-03-docker-base-use.html"
           data-tag="Docker"
           data-author="" >
            <span class="post-title" title="Docker 基本操作">Docker 基本操作</span>
            <span class="post-date" title="2017-10-03 23:38:00">2017/10/03</span>
        </a>
        
        <a id="top" class="后端开发 Redis "
           href="/2018-09-10-distributed-lock.html"
           data-tag="Redis,Nosql"
           data-author="" >
            <span class="post-title" title="分布式锁(redis &amp; zookeeper)">分布式锁(redis &amp; zookeeper)</span>
            <span class="post-date" title="2018-09-10 23:38:23">2018/09/10</span>
        </a>
        
        <a id="top" class="后端开发 Linux "
           href="/2017-09-21-file-descriptor.html"
           data-tag="后端开发,Linux"
           data-author="" >
            <span class="post-title" title="文件描述符（File Descriptor）简介">文件描述符（File Descriptor）简介</span>
            <span class="post-date" title="2017-09-21 09:24:06">2017/09/21</span>
        </a>
        
        <a id="top" class="大数据 Hadoop "
           href="/2018-02-16-hadoop-hdfs-base.html"
           data-tag="大数据,Hadoop"
           data-author="" >
            <span class="post-title" title="HDFS 系统基础介绍及使用(python)">HDFS 系统基础介绍及使用(python)</span>
            <span class="post-date" title="2018-02-16 18:19:32">2018/02/16</span>
        </a>
        
        <a id="top" class="Go Go 语言注意点 "
           href="/2018-11-05-go-the-zero-value-of-struct-is-not-nil.html"
           data-tag="Go"
           data-author="" >
            <span class="post-title" title="Go语言-结构体的零值问题">Go语言-结构体的零值问题</span>
            <span class="post-date" title="2018-11-05 12:58:50">2018/11/05</span>
        </a>
        
        <a id="top" class="大数据 Hive "
           href="/2018-04-23-hive-base.html"
           data-tag="大数据,Hive"
           data-author="" >
            <span class="post-title" title="Hive 基础及实践">Hive 基础及实践</span>
            <span class="post-date" title="2018-04-23 18:19:32">2018/04/23</span>
        </a>
        
        <a id="top" class="大数据 Hive "
           href="/2018-06-30-hive-optimization.html"
           data-tag="大数据,Hive"
           data-author="" >
            <span class="post-title" title="Hive 优化总结">Hive 优化总结</span>
            <span class="post-date" title="2018-06-30 18:19:32">2018/06/30</span>
        </a>
        
        <a id="top" class="环境搭建 "
           href="/2017-10-16-install-hadoop.html"
           data-tag="Hadoop,环境搭建"
           data-author="" >
            <span class="post-title" title="使用 ansible 部署 hadoop 集群">使用 ansible 部署 hadoop 集群</span>
            <span class="post-date" title="2017-10-16 18:19:32">2017/10/16</span>
        </a>
        
        <a id="top" class="环境搭建 "
           href="/2017-10-23-install-hive.html"
           data-tag="Hive,环境搭建"
           data-author="" >
            <span class="post-title" title="使用 ansible 部署 hive （远程 mysql 存储 metadata）">使用 ansible 部署 hive （远程 mysql 存储 metadata）</span>
            <span class="post-date" title="2017-10-23 18:19:32">2017/10/23</span>
        </a>
        
        <a id="top" class="环境搭建 "
           href="/2017-11-28-install-zookeeper.html"
           data-tag="环境搭建,Zookeeper"
           data-author="" >
            <span class="post-title" title="使用 ansible 部署 zookeeper 环境">使用 ansible 部署 zookeeper 环境</span>
            <span class="post-date" title="2017-11-28 12:42:24">2017/11/28</span>
        </a>
        
        <a id="top" class="环境搭建 "
           href="/2017-10-13-install-jdk.html"
           data-tag="环境搭建,Java"
           data-author="" >
            <span class="post-title" title="使用 ansible 部署 java(jdk) 环境">使用 ansible 部署 java(jdk) 环境</span>
            <span class="post-date" title="2017-10-13 18:19:32">2017/10/13</span>
        </a>
        
        <a id="top" class="环境搭建 "
           href="/2017-12-03-install-kafka.html"
           data-tag="环境搭建,Kafka"
           data-author="" >
            <span class="post-title" title="使用 ansible 部署 kafka 集群">使用 ansible 部署 kafka 集群</span>
            <span class="post-date" title="2017-12-03 07:01:41">2017/12/03</span>
        </a>
        
        <a id="top" class="后端开发 Linux "
           href="/2017-05-28-linux-top.html"
           data-tag="后端开发,Linux"
           data-author="" >
            <span class="post-title" title="Linux 命令 top 拆解">Linux 命令 top 拆解</span>
            <span class="post-date" title="2017-05-28 09:24:06">2017/05/28</span>
        </a>
        
        <a id="top" class="大数据 Kafka "
           href="/2017-12-19-kafka-intro.html"
           data-tag="Kafka,消息队列"
           data-author="" >
            <span class="post-title" title="kafka python 客户端使用">kafka python 客户端使用</span>
            <span class="post-date" title="2017-12-19 12:58:50">2017/12/19</span>
        </a>
        
        <a id="top" class="机器学习 算法 "
           href="/2018-03-03-ml-gradient-descent.html"
           data-tag="机器学习,回归"
           data-author="" >
            <span class="post-title" title="梯度下降求解逻辑回归">梯度下降求解逻辑回归</span>
            <span class="post-date" title="2018-03-03 09:24:06">2018/03/03</span>
        </a>
        
        <a id="top" class="机器学习 案例 "
           href="/2018-03-10-ml-linearregression-advertising.html"
           data-tag="机器学习,回归"
           data-author="" >
            <span class="post-title" title="LinearRegression建立广告投放与销售量的模型(sklearn)">LinearRegression建立广告投放与销售量的模型(sklearn)</span>
            <span class="post-date" title="2018-03-10 09:24:06">2018/03/10</span>
        </a>
        
        <a id="top" class="Interesting Music "
           href="/2018-05-17-music-eason-unconditional.html"
           data-tag="音乐"
           data-author="" >
            <span class="post-title" title="温情脉脉 —《无条件》">温情脉脉 —《无条件》</span>
            <span class="post-date" title="2018-05-17 12:58:50">2018/05/17</span>
        </a>
        
        <a id="top" class="机器学习 算法 "
           href="/2018-02-26-ml-regression-pic.html"
           data-tag="机器学习,回归"
           data-author="" >
            <span class="post-title" title="线性回归算法推导">线性回归算法推导</span>
            <span class="post-date" title="2018-02-26 09:24:06">2018/02/26</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-07-30-mysql-authority-management.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySQL 权限管理">MySQL 权限管理</span>
            <span class="post-date" title="2017-07-30 09:24:06">2017/07/30</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-06-20-mysql-binlog.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySQL二进制日志 binlog 详细介绍">MySQL二进制日志 binlog 详细介绍</span>
            <span class="post-date" title="2017-06-20 09:24:06">2017/06/20</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-08-29-mysql-backup-restore.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySQL 备份和恢复机制">MySQL 备份和恢复机制</span>
            <span class="post-date" title="2017-08-29 09:24:06">2017/08/29</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2018-07-08-mysql-commonly-used-tools.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySQL 中的常用工具">MySQL 中的常用工具</span>
            <span class="post-date" title="2018-07-08 09:24:06">2018/07/08</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-07-09-mysql-common-skill.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySQL 常见问题和应用技巧">MySQL 常见问题和应用技巧</span>
            <span class="post-date" title="2017-07-09 09:24:06">2017/07/09</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-07-23-mysql-concurrent-params.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="调整 MySQL 并发相关的参数">调整 MySQL 并发相关的参数</span>
            <span class="post-date" title="2017-07-23 09:24:06">2017/07/23</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-08-07-mysql-index-optimization.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySql 索引优化">MySql 索引优化</span>
            <span class="post-date" title="2017-08-07 09:24:06">2017/08/07</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-06-16-mysql-innodb-log.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySQL Innodb 日志机制及优化">MySQL Innodb 日志机制及优化</span>
            <span class="post-date" title="2017-06-16 09:24:06">2017/06/16</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-07-02-mysql-lock-intro.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySQL 锁机制">MySQL 锁机制</span>
            <span class="post-date" title="2017-07-02 09:24:06">2017/07/02</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-06-24-mysql-log.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySQL 日志介绍">MySQL 日志介绍</span>
            <span class="post-date" title="2017-06-24 09:24:06">2017/06/24</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-08-16-mysql-memory-optimization.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySQL 内存优化">MySQL 内存优化</span>
            <span class="post-date" title="2017-08-16 09:24:06">2017/08/16</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2018-08-26-mysql-optimization.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySQL 性能优化(全面)">MySQL 性能优化(全面)</span>
            <span class="post-date" title="2018-08-26 09:24:06">2018/08/26</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-09-05-mysql-partition.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySql 表分区">MySql 表分区</span>
            <span class="post-date" title="2017-09-05 09:24:06">2017/09/05</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-09-13-mysql-replication.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySQL 主从复制">MySQL 主从复制</span>
            <span class="post-date" title="2017-09-13 09:24:06">2017/09/13</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-06-10-mysql-sql-optimization-steps.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="优化 sql 语句的一般步骤">优化 sql 语句的一般步骤</span>
            <span class="post-date" title="2017-06-10 09:24:06">2017/06/10</span>
        </a>
        
        <a id="top" class="大数据 数据分析 "
           href="/2018-02-18-pandas-intro.html"
           data-tag="Pandas"
           data-author="" >
            <span class="post-title" title="pandas 入门练习">pandas 入门练习</span>
            <span class="post-date" title="2018-02-18 11:20:47">2018/02/18</span>
        </a>
        
        <a id="top" class="后端开发 MySQL "
           href="/2017-08-22-mysql-select-optimization.html"
           data-tag="后端开发,MySQL"
           data-author="" >
            <span class="post-title" title="MySQL 查询优化">MySQL 查询优化</span>
            <span class="post-date" title="2017-08-22 09:24:06">2017/08/22</span>
        </a>
        
        <a id="top" class="大数据 数据分析 "
           href="/2018-02-10-numpy-intro.html"
           data-tag="Numpy"
           data-author="" >
            <span class="post-title" title="numpy 入门练习">numpy 入门练习</span>
            <span class="post-date" title="2018-02-10 11:20:47">2018/02/10</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-04-03-pyspark-custom-accumulator.html"
           data-tag="Spark,开发"
           data-author="" >
            <span class="post-title" title="pyspark 自定义累加器(python)">pyspark 自定义累加器(python)</span>
            <span class="post-date" title="2018-04-03 11:20:47">2018/04/03</span>
        </a>
        
        <a id="top" class="Python "
           href="/2018-05-22-python-singleton.html"
           data-tag="Python"
           data-author="" >
            <span class="post-title" title="四种 python 实现的单例模式的方式">四种 python 实现的单例模式的方式</span>
            <span class="post-date" title="2018-05-22 09:24:06">2018/05/22</span>
        </a>
        
        <a id="top" class="后端开发 Redis "
           href="/2018-08-11-redis-basic.html"
           data-tag="Redis,Nosql"
           data-author="" >
            <span class="post-title" title="Redis 数据类型及应用场景">Redis 数据类型及应用场景</span>
            <span class="post-date" title="2018-08-11 23:38:23">2018/08/11</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-01-01-pyspark-read-write.html"
           data-tag="Spark,开发"
           data-author="" >
            <span class="post-title" title="Spark 读取和转存数据(python)">Spark 读取和转存数据(python)</span>
            <span class="post-date" title="2018-01-01 07:34:19">2018/01/01</span>
        </a>
        
        <a id="top" class="后端开发 Redis "
           href="/2018-03-21-redis-cluster.html"
           data-tag="Redis,Nosql"
           data-author="" >
            <span class="post-title" title="Redis Cluster 介绍">Redis Cluster 介绍</span>
            <span class="post-date" title="2018-03-21 23:38:23">2018/03/21</span>
        </a>
        
        <a id="top" class="后端开发 Redis "
           href="/2017-11-07-redis-persistence.html"
           data-tag="Redis,Nosql"
           data-author="" >
            <span class="post-title" title="Redis 持久化介绍(RDB 和 AOF)">Redis 持久化介绍(RDB 和 AOF)</span>
            <span class="post-date" title="2017-11-07 23:38:23">2017/11/07</span>
        </a>
        
        <a id="top" class="后端开发 Redis "
           href="/2017-11-15-redis-replication.html"
           data-tag="Redis,Nosql"
           data-author="" >
            <span class="post-title" title="Redis Replication 原理是实践">Redis Replication 原理是实践</span>
            <span class="post-date" title="2017-11-15 23:38:23">2017/11/15</span>
        </a>
        
        <a id="top" class="后端开发 Redis "
           href="/2018-03-16-redis-sentinel.html"
           data-tag="Redis,Nosql"
           data-author="" >
            <span class="post-title" title="Redis 哨兵(sentinal)">Redis 哨兵(sentinal)</span>
            <span class="post-date" title="2018-03-16 23:38:23">2018/03/16</span>
        </a>
        
        <a id="top" class="后端开发 RPC "
           href="/2018-05-27-rpc-distribute-zookeeper-python.html"
           data-tag="后端开发,RPC"
           data-author="" >
            <span class="post-title" title="基于zookeeper的分布式RPC(python)">基于zookeeper的分布式RPC(python)</span>
            <span class="post-date" title="2018-05-27 09:24:06">2018/05/27</span>
        </a>
        
        <a id="top" class="后端开发 RPC "
           href="/2018-05-23-rpc-basic-python.html"
           data-tag="后端开发,RPC"
           data-author="" >
            <span class="post-title" title="RPC 模型基础知识(python)">RPC 模型基础知识(python)</span>
            <span class="post-date" title="2018-05-23 09:24:06">2018/05/23</span>
        </a>
        
        <a id="top" class="后端开发 RPC "
           href="/2018-06-01-rpc-grpc-python-ping.html"
           data-tag="后端开发,RPC"
           data-author="" >
            <span class="post-title" title="grpc开发入门(python)">grpc开发入门(python)</span>
            <span class="post-date" title="2018-06-01 09:24:06">2018/06/01</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-01-09-spark-and-sql-join-pattern.html"
           data-tag="Spark,开发"
           data-author="" >
            <span class="post-title" title="快速区分 spark 四种关联方式(结论适用于 sql)">快速区分 spark 四种关联方式(结论适用于 sql)</span>
            <span class="post-date" title="2018-01-09 11:20:47">2018/01/09</span>
        </a>
        
        <a id="top" class="后端开发 RPC "
           href="/2018-05-16-rpc-protocol-basic.html"
           data-tag="后端开发,RPC"
           data-author="" >
            <span class="post-title" title="RPC 消息协议设计注意点">RPC 消息协议设计注意点</span>
            <span class="post-date" title="2018-05-16 09:24:06">2018/05/16</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-04-22-spark-app-area-top3-product.html"
           data-tag="Spark,开发"
           data-author="" >
            <span class="post-title" title="各区域热门商品统计(pyspark)">各区域热门商品统计(pyspark)</span>
            <span class="post-date" title="2018-04-22 09:24:06">2018/04/22</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-04-20-spark-app-page-convert-rate.html"
           data-tag="Spark,开发"
           data-author="" >
            <span class="post-title" title="计算页面单跳转化率(pyspark)">计算页面单跳转化率(pyspark)</span>
            <span class="post-date" title="2018-04-20 09:24:06">2018/04/20</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-04-19-spark-app-session-analysis.html"
           data-tag="Spark,开发"
           data-author="" >
            <span class="post-title" title="用户行为分析(pyspark)">用户行为分析(pyspark)</span>
            <span class="post-date" title="2018-04-19 09:24:06">2018/04/19</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-02-02-spark-base-optimization.html"
           data-tag="Spark,性能调优"
           data-author="" >
            <span class="post-title" title="spark 性能优化方法">spark 性能优化方法</span>
            <span class="post-date" title="2018-02-02 09:24:06">2018/02/02</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-01-22-spark-functions-optimization.html"
           data-tag="Spark,性能调优"
           data-author="" >
            <span class="post-title" title="Spark 算子调优方法">Spark 算子调优方法</span>
            <span class="post-date" title="2018-01-22 09:24:06">2018/01/22</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2017-12-25-spark-operating-mechanism.html"
           data-tag="Spark,原理"
           data-author="" >
            <span class="post-title" title="Spark 运行机制">Spark 运行机制</span>
            <span class="post-date" title="2017-12-25 11:20:47">2017/12/25</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-01-01-spark-rdd-dependence.html"
           data-tag="Spark,Spark 原理"
           data-author="" >
            <span class="post-title" title="Spark RDD 的 窄依赖和宽依赖(以 wordcount 程序为例)">Spark RDD 的 窄依赖和宽依赖(以 wordcount 程序为例)</span>
            <span class="post-date" title="2018-01-01 09:24:06">2018/01/01</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-07-19-spark-shuffle-optimization.html"
           data-tag="Spark,性能调优"
           data-author="" >
            <span class="post-title" title="Spark Shuffle 性能调优">Spark Shuffle 性能调优</span>
            <span class="post-date" title="2018-07-19 11:20:47">2018/07/19</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-06-19-spark-sql-rdd.html"
           data-tag="Spark,开发"
           data-author="" >
            <span class="post-title" title="Spark Sql 两种将 RDD 转为 DataFrame 的方式">Spark Sql 两种将 RDD 转为 DataFrame 的方式</span>
            <span class="post-date" title="2018-06-19 11:20:47">2018/06/19</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-01-17-spark-standalone.html"
           data-tag="Spark,原理"
           data-author="" >
            <span class="post-title" title="Spark Standalone 运行模式">Spark Standalone 运行模式</span>
            <span class="post-date" title="2018-01-17 11:20:47">2018/01/17</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-06-10-spark-streaming-checkpoint.html"
           data-tag="Spark,开发"
           data-author="" >
            <span class="post-title" title="Spark Streaming 使用 checkpoint 做恢复">Spark Streaming 使用 checkpoint 做恢复</span>
            <span class="post-date" title="2018-06-10 11:20:47">2018/06/10</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-04-24-spark-streaming-transform.html"
           data-tag="Spark,开发"
           data-author="" >
            <span class="post-title" title="sparkStreaming 实时黑名单过滤(pyspark)">sparkStreaming 实时黑名单过滤(pyspark)</span>
            <span class="post-date" title="2018-04-24 11:20:47">2018/04/24</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-05-02-spark-streaming-sql-top3.html"
           data-tag="Spark,开发"
           data-author="" >
            <span class="post-title" title="Spark Streaming 与 spark sql 结合实时统计点击量top3商品">Spark Streaming 与 spark sql 结合实时统计点击量top3商品</span>
            <span class="post-date" title="2018-05-02 11:20:47">2018/05/02</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-04-25-spark-streaming-window.html"
           data-tag="Spark,开发"
           data-author="" >
            <span class="post-title" title="Spark Streaming 热点搜索词滑动统计(pyspark)">Spark Streaming 热点搜索词滑动统计(pyspark)</span>
            <span class="post-date" title="2018-04-25 11:20:47">2018/04/25</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-04-23-spark-updatestatebykey.html"
           data-tag="Spark,开发"
           data-author="" >
            <span class="post-title" title="UpdateStateByKey 实时统计全局wordcount(pyspark)">UpdateStateByKey 实时统计全局wordcount(pyspark)</span>
            <span class="post-date" title="2018-04-23 11:20:47">2018/04/23</span>
        </a>
        
        <a id="top" class="大数据 Spark "
           href="/2018-01-27-spark-yarn-client-cluster.html"
           data-tag="Spark,原理"
           data-author="" >
            <span class="post-title" title="Spark 的 Yarn-cluster 和 Yarn-client 提交模式">Spark 的 Yarn-cluster 和 Yarn-client 提交模式</span>
            <span class="post-date" title="2018-01-27 09:24:06">2018/01/27</span>
        </a>
        
        <a id="top" class="后端开发 Linux "
           href="/2017-09-25-supervisor-intro.html"
           data-tag="工具"
           data-author="" >
            <span class="post-title" title="进程管理工具 supervisor">进程管理工具 supervisor</span>
            <span class="post-date" title="2017-09-25 11:20:47">2017/09/25</span>
        </a>
        
        <a id="top" class="大数据 Zookeeper "
           href="/2017-11-25-zookeeper-intro.html"
           data-tag="大数据,分布式协作框架"
           data-author="" >
            <span class="post-title" title="zookeeper概述(应用场景及基本概念)">zookeeper概述(应用场景及基本概念)</span>
            <span class="post-date" title="2017-11-25 09:23:42">2017/11/25</span>
        </a>
        
        <a id="top" class="后端开发 Linux "
           href="/2017-05-14-uid-euid-gid-egid-introduce.html"
           data-tag="Linux 权限问题"
           data-author="" >
            <span class="post-title" title="关于 Linux 进程的 UID、EUID、GID 和 EGID">关于 Linux 进程的 UID、EUID、GID 和 EGID</span>
            <span class="post-date" title="2017-05-14 17:13:00">2017/05/14</span>
        </a>
        
        <a id="top" class="大数据 Zookeeper "
           href="/2018-10-03-zookeeper-kazoo-usage.html"
           data-tag="大数据,分布式协作框架"
           data-author="" >
            <span class="post-title" title="zookeeper python 客户端 kazoo 使用指南(译自官网)">zookeeper python 客户端 kazoo 使用指南(译自官网)</span>
            <span class="post-date" title="2018-10-03 09:23:42">2018/10/03</span>
        </a>
        
        <a id="top" class="算法与数据结构 基础 "
           href="/2017-05-21-algorithm-efficiency-analysis.html"
           data-tag="时间复杂度,大O算法"
           data-author="" >
            <span class="post-title" title="算法效率分析">算法效率分析</span>
            <span class="post-date" title="2017-05-21 09:24:06">2017/05/21</span>
        </a>
        
    </nav>
</div>
    </div>
    <div class="hide-list">
        <div class="semicircle">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div class="post">
    <div class="pjax">
        <article id="post-pyspark-read-write" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">Spark 读取和转存数据(python)</h1>
    
    <div class="article-meta">
        
        <span class="top"><a>置顶</a></span>
        
        
        
        <span class="book">
            
                <a  data-rel="大数据">大数据</a>/
            
                <a  data-rel="Spark">Spark</a>
            
        </span>
        
        
        <span class="tag">
            
            <a class="color1">Spark</a>
            
            <a class="color3">开发</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
        创建时间:<time class="date" title='更新时间: 2019-12-28 14:03:59'>2018-01-01 07:34</time>
        
    </div>
    <div class="article-meta">
        
        <span>字数:2.1k</span>
        
        
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-rdd-读取和转存数据"><span class="toc-text">spark rdd 读取和转存数据</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#通过集合创建rdd-测试用"><span class="toc-text">通过集合创建rdd(测试用)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#本地文件系统读写"><span class="toc-text">本地文件系统读写</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#分布式文件系统HDFS的数据读写"><span class="toc-text">分布式文件系统HDFS的数据读写</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#读取-json-格式文件"><span class="toc-text">读取 json 格式文件</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-Sql-读取和转存数据"><span class="toc-text">Spark Sql 读取和转存数据</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#读取本地-json-文件"><span class="toc-text">读取本地 json 文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#从-RDD-转换到-DataFrame"><span class="toc-text">从 RDD 转换到 DataFrame</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#利用反射机制推断-RDD-模式"><span class="toc-text">利用反射机制推断 RDD 模式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#以编程的方式指定Schema"><span class="toc-text">以编程的方式指定Schema</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#转存-dataFrame-为格式化文件"><span class="toc-text">转存 dataFrame 为格式化文件</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#直接转为格式化文件"><span class="toc-text">直接转为格式化文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#先转为-rdd-再转为文件"><span class="toc-text">先转为 rdd, 再转为文件</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#读写-parquet-文件"><span class="toc-text">读写 parquet 文件</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#读取-parquet-文件"><span class="toc-text">读取 parquet 文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#转存-parquet-文件"><span class="toc-text">转存 parquet 文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#重新加载转存的-parquet-文件"><span class="toc-text">重新加载转存的 parquet 文件</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#通过-jdbc-读写-mysql"><span class="toc-text">通过 jdbc 读写 mysql</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#环境准备"><span class="toc-text">环境准备</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#MYSQL-环境示例准备"><span class="toc-text">MYSQL 环境示例准备</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#spark-sql-从-mysql-读取数据"><span class="toc-text">spark sql 从 mysql 读取数据</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#spark-sql-写数据到-mysql"><span class="toc-text">spark sql 写数据到 mysql</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-streaming-读取数据"><span class="toc-text">spark streaming 读取数据</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#spark-streaming-基本步骤"><span class="toc-text">spark streaming 基本步骤</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#从文件流读取数据"><span class="toc-text">从文件流读取数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#从-socket流-中读取数据"><span class="toc-text">从 socket流 中读取数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#使用-list-或-rdds-创建输入流-用于测试"><span class="toc-text">使用 list 或 rdds 创建输入流(用于测试)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#kafka-作为数据源"><span class="toc-text">kafka 作为数据源</span></a></li></ol></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>介绍 spark core， spark sql 和 spark streaming 读取多种数据源及数据转存</p>
<a id="more"></a>
<h3 id="spark-rdd-读取和转存数据"><a href="#spark-rdd-读取和转存数据" class="headerlink" title="spark rdd 读取和转存数据"></a>spark rdd 读取和转存数据</h3><h4 id="通过集合创建rdd-测试用"><a href="#通过集合创建rdd-测试用" class="headerlink" title="通过集合创建rdd(测试用)"></a>通过集合创建rdd(测试用)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">list &#x3D; [&quot;hadoop&quot;, &quot;spark&quot;, &quot;hive&quot;]</span><br><span class="line">rdd &#x3D;  sc.parallelize(list)</span><br></pre></td></tr></table></figure>
<h4 id="本地文件系统读写"><a href="#本地文件系统读写" class="headerlink" title="本地文件系统读写"></a>本地文件系统读写</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 读文件&#x2F;目录</span><br><span class="line">rdd &#x3D; sc.textFile(&quot;file:&#x2F;&#x2F;&#x2F;home&#x2F;zj&#x2F;word.txt&quot;)</span><br><span class="line"># 存文件</span><br><span class="line">rdd.saveAsTextFile(&quot;file:&#x2F;&#x2F;&#x2F;home&#x2F;zj&#x2F;word_bak.txt&quot;)</span><br><span class="line">#</span><br></pre></td></tr></table></figure>
<p>注意存文件的时候, <code>wrod_bak.txt</code> 并不是文件而是一个文件夹  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; ls &#x2F;home&#x2F;zj&#x2F;word_bak.txt</span><br><span class="line">part-00000</span><br><span class="line">_SUCCESS</span><br></pre></td></tr></table></figure>
<p>part-00000 中就是存数据的文件</p>
<h4 id="分布式文件系统HDFS的数据读写"><a href="#分布式文件系统HDFS的数据读写" class="headerlink" title="分布式文件系统HDFS的数据读写"></a>分布式文件系统HDFS的数据读写</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 上传文件到 hdfs</span><br><span class="line">shell&gt; hdfs dfs -put &#x2F;home&#x2F;zj&#x2F;word.txt &#x2F;user&#x2F;zj&#x2F;word.txt</span><br><span class="line"># 读文件&#x2F;目录</span><br><span class="line">rdd &#x3D; sc.textFile(&quot;hdfs:&#x2F;&#x2F;localhost:9000&#x2F;user&#x2F;zj&#x2F;word.txt&quot;)</span><br><span class="line">rdd &#x3D; sc.textFile(&quot;&#x2F;user&#x2F;zj&#x2F;word.txt&quot;)</span><br><span class="line"># 存文件</span><br><span class="line">rdd.saveAsTextFile(&quot;word_bak.txt&quot;)</span><br></pre></td></tr></table></figure>
<p>同样的,这里存的 <code>word_bak.txt</code> 也是一个目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; hsfs dfs -ls &#x2F;user&#x2F;zj&#x2F;word_bak.txt</span><br><span class="line">part-00000</span><br><span class="line">_SUCCESS</span><br></pre></td></tr></table></figure>
<h4 id="读取-json-格式文件"><a href="#读取-json-格式文件" class="headerlink" title="读取 json 格式文件"></a>读取 json 格式文件</h4><p>需要使用map操作对读取到的json文件内容进行转换  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># &#x2F;home&#x2F;zjprople.json</span><br><span class="line">&#123;&quot;name&quot;:&quot;Michael&quot;&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;Andy&quot;, &quot;age&quot;:30&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;Justin&quot;, &quot;age&quot;:19&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark import SparkContext</span><br><span class="line">import json</span><br><span class="line">sc &#x3D; SparkContext(&#39;local&#39;,&#39;json&#39;)</span><br><span class="line">inputFile &#x3D;  &quot;file:&#x2F;&#x2F;&#x2F;home&#x2F;zj&#x2F;people.json&quot;</span><br><span class="line">jsonStrs &#x3D; sc.textFile(inputFile)</span><br><span class="line">result &#x3D; jsonStrs.map(lambda s : json.loads(s))</span><br><span class="line">result.foreach(print)</span><br></pre></td></tr></table></figure>

<h3 id="Spark-Sql-读取和转存数据"><a href="#Spark-Sql-读取和转存数据" class="headerlink" title="Spark Sql 读取和转存数据"></a>Spark Sql 读取和转存数据</h3><h4 id="读取本地-json-文件"><a href="#读取本地-json-文件" class="headerlink" title="读取本地 json 文件"></a>读取本地 json 文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark&#x3D;SparkSession.builder.getOrCreate()</span><br><span class="line">df &#x3D; spark.read.json(&quot;file:&#x2F;&#x2F;&#x2F;usr&#x2F;local&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;resources&#x2F;people.json&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="从-RDD-转换到-DataFrame"><a href="#从-RDD-转换到-DataFrame" class="headerlink" title="从 RDD 转换到 DataFrame"></a>从 RDD 转换到 DataFrame</h4><h5 id="利用反射机制推断-RDD-模式"><a href="#利用反射机制推断-RDD-模式" class="headerlink" title="利用反射机制推断 RDD 模式"></a>利用反射机制推断 RDD 模式</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">from pyspark.sql.types import Row</span><br><span class="line"></span><br><span class="line">spark &#x3D; SparkSession\</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(&quot;reflect rdd to dataFrame&quot;) \</span><br><span class="line">    .getOrCreate()</span><br><span class="line">sc &#x3D; spark.sparkContext</span><br><span class="line"># Michael, 29</span><br><span class="line"># Andy, 30</span><br><span class="line"># Justin, 19</span><br><span class="line">lines &#x3D; sc.textFile(&quot;file:&#x2F;&#x2F;&#x2F;usr&#x2F;local&#x2F;spark-2.2.1&#x2F;examples&#x2F;src&#x2F;main&#x2F;resources&#x2F;people.txt&quot;)</span><br><span class="line">parts &#x3D; lines.map(lambda l: l.split(&quot;,&quot;))</span><br><span class="line">people &#x3D; parts.map(lambda p: Row(name&#x3D;p[0], age&#x3D;int(p[1])))</span><br><span class="line"></span><br><span class="line">schemaPeople &#x3D; spark.createDataFrame(people)</span><br><span class="line">schemaPeople.createOrReplaceTempView(&quot;people&quot;)</span><br><span class="line"></span><br><span class="line">teenagers &#x3D; spark.sql(&quot;SELECT name FROM people WHERE age &gt;&#x3D; 13 AND age &lt;&#x3D;19&quot;)</span><br><span class="line"></span><br><span class="line">teenNames &#x3D; teenagers.rdd.map(lambda p: &quot;Name: &quot; + p.name).collect()</span><br><span class="line">for name in teenNames:</span><br><span class="line">    print(name)</span><br></pre></td></tr></table></figure>

<h5 id="以编程的方式指定Schema"><a href="#以编程的方式指定Schema" class="headerlink" title="以编程的方式指定Schema"></a>以编程的方式指定Schema</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">from pyspark.sql.types import StructField, StructType, StringType</span><br><span class="line">spark &#x3D; SparkSession\</span><br><span class="line">    .builder\</span><br><span class="line">    .appName(&quot;coding_rdd&quot;)\</span><br><span class="line">    .getOrCreate()</span><br><span class="line"></span><br><span class="line">sc &#x3D; spark.sparkContext</span><br><span class="line"></span><br><span class="line">lines &#x3D; sc.textFile(&quot;file:&#x2F;&#x2F;&#x2F;usr&#x2F;local&#x2F;spark-2.2.1&#x2F;examples&#x2F;src&#x2F;main&#x2F;resources&#x2F;people.txt&quot;)</span><br><span class="line">parts &#x3D; lines.map(lambda l: l.split(&quot;,&quot;))</span><br><span class="line">people &#x3D; parts.map(lambda p: (p[0], p[1].strip()))</span><br><span class="line"></span><br><span class="line"># 定义 schema</span><br><span class="line">schemaString &#x3D; &quot;name age&quot;</span><br><span class="line"></span><br><span class="line">fields &#x3D; [StructField(field_name, StringType(), True) for field_name in schemaString.split()]</span><br><span class="line">schema &#x3D; StructType(fields)</span><br><span class="line"></span><br><span class="line">schemaPeople &#x3D; spark.createDataFrame(people, schema)</span><br><span class="line"># 必须注册为临时表才能供下面查询使用</span><br><span class="line">schemaPeople.createOrReplaceTempView(&quot;people&quot;)</span><br><span class="line">results &#x3D; spark.sql(&quot;SELECT name FROM people&quot;)</span><br><span class="line">results.show()</span><br></pre></td></tr></table></figure>

<h4 id="转存-dataFrame-为格式化文件"><a href="#转存-dataFrame-为格式化文件" class="headerlink" title="转存 dataFrame 为格式化文件"></a>转存 dataFrame 为格式化文件</h4><h5 id="直接转为格式化文件"><a href="#直接转为格式化文件" class="headerlink" title="直接转为格式化文件"></a>直接转为格式化文件</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">peopleDF &#x3D; spark.read.format(&quot;json&quot;).load(&quot;file:&#x2F;&#x2F;&#x2F;usr&#x2F;local&#x2F;spark-2.2.1&#x2F;examples&#x2F;src&#x2F;main&#x2F;resources&#x2F;people.json&quot;)</span><br><span class="line"># 转为为 csv 文件</span><br><span class="line">peopleDF.select(&quot;name&quot;, &quot;age&quot;).write.format(&quot;csv&quot;).save(&quot;file:&#x2F;&#x2F;&#x2F;usr&#x2F;local&#x2F;spark-2.2.1&#x2F;examples&#x2F;src&#x2F;main&#x2F;resources&#x2F;newpeople.csv&quot;)</span><br></pre></td></tr></table></figure>
<h5 id="先转为-rdd-再转为文件"><a href="#先转为-rdd-再转为文件" class="headerlink" title="先转为 rdd, 再转为文件"></a>先转为 rdd, 再转为文件</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">peopleDF.rdd.saveAsTextFile(&quot;file:&#x2F;&#x2F;&#x2F;usr&#x2F;local&#x2F;spark-2.2.1&#x2F;examples&#x2F;src&#x2F;main&#x2F;resources&#x2F;newpeople.txt&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="读写-parquet-文件"><a href="#读写-parquet-文件" class="headerlink" title="读写 parquet 文件"></a>读写 parquet 文件</h4><h5 id="读取-parquet-文件"><a href="#读取-parquet-文件" class="headerlink" title="读取 parquet 文件"></a>读取 parquet 文件</h5><p>Parquet 是许多其他数据处理系统支持的 columnar format （列式存储）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">parquetFileDF &#x3D; spark.read.parquet(&quot;file:&#x2F;&#x2F;&#x2F;usr&#x2F;local&#x2F;spark-2.2.1&#x2F;examples&#x2F;src&#x2F;main&#x2F;resources&#x2F;users.parquet&quot;</span><br><span class="line">parquetFileDF.createOrReplaceTempView(&quot;parquetFile&quot;)</span><br><span class="line">namesDF &#x3D; spark.sql(&quot;SELECT * FROM parquetFile&quot;)</span><br><span class="line">namesDF.rdd.foreach(lambda person: print(person.name))</span><br></pre></td></tr></table></figure>
<h5 id="转存-parquet-文件"><a href="#转存-parquet-文件" class="headerlink" title="转存 parquet 文件"></a>转存 parquet 文件</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">peopleDF.write.parquet(&quot;file:&#x2F;&#x2F;&#x2F;usr&#x2F;local&#x2F;spark-2.2.1&#x2F;examples&#x2F;src&#x2F;main&#x2F;resources&#x2F;newpeople.parquet&quot;)</span><br></pre></td></tr></table></figure>

<h5 id="重新加载转存的-parquet-文件"><a href="#重新加载转存的-parquet-文件" class="headerlink" title="重新加载转存的 parquet 文件"></a>重新加载转存的 parquet 文件</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">peopleDF &#x3D; spark.read.parquet(&quot;file:&#x2F;&#x2F;&#x2F;usr&#x2F;local&#x2F;spark&#x2F;myCode&#x2F;people.parquet&quot;)</span><br></pre></td></tr></table></figure>

<h4 id="通过-jdbc-读写-mysql"><a href="#通过-jdbc-读写-mysql" class="headerlink" title="通过 jdbc 读写 mysql"></a>通过 jdbc 读写 mysql</h4><h5 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h5><p>使用 jdbc 连接 mysql 必须要导入需要的ja包, 比如 mysql-connector-java-5.1.46.jar</p>
<ol>
<li>下载地址: <a href="https://dev.mysql.com/downloads/connector/j/" target="_blank" rel="noopener">https://dev.mysql.com/downloads/connector/j/</a></li>
<li>下载后解压到指定目录 /usr/local/spark-2.2.1/jars/</li>
<li>编辑 spark 根目录下的 /conf/spark-env.sh, 把目标jar包写入环境变量 SPARK_DIST_CLASSPATH<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_DIST_CLASSPATH&#x3D;$(&#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;bin&#x2F;hadoop classpath):&#x2F;usr&#x2F;local&#x2F;spark-2.2.1&#x2F;jars&#x2F;mysql-connector-java-5.1.46&#x2F;mysql-connector-java-5.1.46-bin.jar</span><br></pre></td></tr></table></figure>
<h5 id="MYSQL-环境示例准备"><a href="#MYSQL-环境示例准备" class="headerlink" title="MYSQL 环境示例准备"></a>MYSQL 环境示例准备</h5></li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">MySQL [none]&gt; create database spark;</span><br><span class="line">MySQL [none]&gt;  use spark;</span><br><span class="line">MySQL [spark]&gt; create table people(id int unsigned auto_increment primary key, name char(20), age int(4);</span><br><span class="line">MySQL [spark]&gt; insert into people (name, age) values  (&quot;Mchael&quot;, 29),(&quot;Andy&quot;, 30),(&quot;Justn&quot;, 19);</span><br><span class="line">MySQL [spark]&gt; select * from people;</span><br><span class="line">+----+--------+------+</span><br><span class="line">| id | name   | age  |</span><br><span class="line">+----+--------+------+</span><br><span class="line">|  1 | Mchael |   29 |</span><br><span class="line">|  2 | Andy   |   30 |</span><br><span class="line">|  3 | Justn  |   19 |</span><br><span class="line">+----+--------+------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>
<h5 id="spark-sql-从-mysql-读取数据"><a href="#spark-sql-从-mysql-读取数据" class="headerlink" title="spark sql 从 mysql 读取数据"></a>spark sql 从 mysql 读取数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line"></span><br><span class="line">spark &#x3D; SparkSession\</span><br><span class="line">    .builder\</span><br><span class="line">    .appName(&quot;coding_rdd&quot;)\</span><br><span class="line">    .getOrCreate()</span><br><span class="line"></span><br><span class="line">jdbcDF &#x3D; spark.read \</span><br><span class="line">    .format(&quot;jdbc&quot;) \</span><br><span class="line">    .option(&quot;url&quot;, &quot;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;spark&quot;) \</span><br><span class="line">    .option(&quot;dbtable&quot;, &quot;people&quot;) \</span><br><span class="line">    .option(&quot;user&quot;, &quot;root&quot;) \</span><br><span class="line">    .option(&quot;password&quot;, &quot;000000&quot;) \</span><br><span class="line">    .option(&quot;driver&quot;, &quot;com.mysql.jdbc.Driver&quot;) \</span><br><span class="line">    .load()</span><br><span class="line"></span><br><span class="line">jdbcDF.show()</span><br></pre></td></tr></table></figure>
<p>执行: python3 datasource_jdbc.py</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+---+------+---+</span><br><span class="line">| id|  name|age|</span><br><span class="line">+---+------+---+</span><br><span class="line">|  1|Mchael| 29|</span><br><span class="line">|  2|  Andy| 30|</span><br><span class="line">|  3| Justn| 19|</span><br><span class="line">+---+------+---+</span><br></pre></td></tr></table></figure>

<p>如果不想在 /conf/spark-env.sh 中写入环境变量,也可以使用 spark-submit 指令指定 jar 包的地址:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --driver-class-path &#x2F;usr&#x2F;local&#x2F;spark-2.2.1&#x2F;jars&#x2F;mysql-connector-java-5.1.46&#x2F;mysql-connector-java-5.1.46-bin.jar datasource_jdbc.py</span><br></pre></td></tr></table></figure>
<h5 id="spark-sql-写数据到-mysql"><a href="#spark-sql-写数据到-mysql" class="headerlink" title="spark sql 写数据到 mysql"></a>spark sql 写数据到 mysql</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">from pyspark.sql.types import Row</span><br><span class="line"></span><br><span class="line">spark &#x3D; SparkSession\</span><br><span class="line">    .builder\</span><br><span class="line">    .appName(&quot;write_DF_to_mysql&quot;)\</span><br><span class="line">    .getOrCreate()</span><br><span class="line">sc &#x3D; spark.sparkContext</span><br><span class="line"></span><br><span class="line"># mmysql 表id字段设置为 AUTO_INCREMENT, 这里就可以不填充 id 字段</span><br><span class="line">peoplelist &#x3D; [</span><br><span class="line">    &quot;zj 25&quot;,</span><br><span class="line">    &quot;kobe 41&quot;</span><br><span class="line">]</span><br><span class="line">peopleRDD &#x3D; sc.parallelize(peoplelist)</span><br><span class="line">people &#x3D; peopleRDD\</span><br><span class="line">    .map(lambda l: l.split())\</span><br><span class="line">    .map(lambda p: Row(name&#x3D;p[0], age&#x3D;p[1]))</span><br><span class="line"></span><br><span class="line">peopleDF &#x3D; spark.createDataFrame(people)</span><br><span class="line"></span><br><span class="line">peopleDF.write\</span><br><span class="line">    .format(&quot;jdbc&quot;)\</span><br><span class="line">    .option(&quot;url&quot;, &quot;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;spark&quot;)\</span><br><span class="line">    .option(&quot;dbtable&quot;, &quot;people&quot;) \</span><br><span class="line">    .option(&quot;user&quot;, &quot;root&quot;) \</span><br><span class="line">    .option(&quot;password&quot;, &quot;000000&quot;) \</span><br><span class="line">    .option(&quot;driver&quot;, &quot;com.mysql.jdbc.Driver&quot;) \</span><br><span class="line">    .mode(&quot;append&quot;)\</span><br><span class="line">    .save()</span><br><span class="line"></span><br><span class="line"># 第二种写法</span><br><span class="line"># prop &#x3D; &#123;</span><br><span class="line">#     &#39;user&#39;: &#39;root&#39;,</span><br><span class="line">#     &#39;password&#39;: &#39;000000&#39;,</span><br><span class="line">#     &#39;driver&#39;: &#39;com.mysql.jdbc.Driver&#39;</span><br><span class="line"># &#125;</span><br><span class="line"># peopleDF.write\</span><br><span class="line">#     .jdbc(&quot;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;spark&quot;,&#39;people&#39;,&#39;append&#39;, prop)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">MySQL [spark]&gt; select * from people;</span><br><span class="line">+----+--------+------+</span><br><span class="line">| id | name   | age  |</span><br><span class="line">+----+--------+------+</span><br><span class="line">|  1 | Mchael |   29 |</span><br><span class="line">|  2 | Andy   |   30 |</span><br><span class="line">|  3 | Justn  |   19 |</span><br><span class="line">|  4 | zj     |   25 |</span><br><span class="line">|  5 | kobe   |   41 |</span><br></pre></td></tr></table></figure>

<h3 id="spark-streaming-读取数据"><a href="#spark-streaming-读取数据" class="headerlink" title="spark streaming 读取数据"></a>spark streaming 读取数据</h3><h4 id="spark-streaming-基本步骤"><a href="#spark-streaming-基本步骤" class="headerlink" title="spark streaming 基本步骤"></a>spark streaming 基本步骤</h4><ol>
<li>定义输入源</li>
<li>通过对DStream应用转换操作和输出操作来定义流计算。</li>
<li>用streamingContext.start()来开始接收数据和处理流程。</li>
<li>通过streamingContext.awaitTermination()方法来等待处理结束（手动结束或因为错误而结束）。</li>
<li>可以通过streamingContext.stop()来手动结束流计算进程。</li>
</ol>
<h4 id="从文件流读取数据"><a href="#从文件流读取数据" class="headerlink" title="从文件流读取数据"></a>从文件流读取数据</h4><p>spark 可以读取一个文件或文件夹下的增量数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from pyspark import SparkContext</span><br><span class="line">from pyspark.streaming import StreamingContext</span><br><span class="line"></span><br><span class="line">#local[*] 中必须设置大于1的并行数量</span><br><span class="line">sc &#x3D; SparkContext(&quot;local[2]&quot;, &quot;streaming&quot;)</span><br><span class="line"># 设置每次计算的时间间隔</span><br><span class="line">ssc &#x3D; StreamingContext(sc, 5)</span><br><span class="line">lines &#x3D; ssc.textFileStream(&#39;file:&#x2F;&#x2F;&#x2F;home&#x2F;zj&#x2F;logs&#39;)</span><br><span class="line">words &#x3D; lines.flatMap(lambda l: l.split())</span><br><span class="line">wordsPair &#x3D; words.map(lambda x: (x, 1))</span><br><span class="line">wordscount &#x3D; wordsPair.reduceByKey(lambda a, b: a + b)</span><br><span class="line">wordscount.pprint()</span><br><span class="line"></span><br><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure>
<p>执行后,向 <code>/home/zj/logs</code> 中添加一个新的包含内容的文件, spark 就可以实时读取到增量数据,进行计算</p>
<h4 id="从-socket流-中读取数据"><a href="#从-socket流-中读取数据" class="headerlink" title="从 socket流 中读取数据"></a>从 socket流 中读取数据</h4><p>Spark Streaming可以通过Socket端口监听并接收数据，然后进行相应处理。</p>
<p>先执行 <code>nc -lk 9999</code>, 然后再执行下面的代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.streaming import StreamingContext</span><br><span class="line">from pyspark import SparkContext</span><br><span class="line"></span><br><span class="line">sc &#x3D; SparkContext(&quot;local[2]&quot;, &quot;streaming_socket&quot;)</span><br><span class="line">ssc &#x3D; StreamingContext(sc, 10)</span><br><span class="line"></span><br><span class="line">lines &#x3D; ssc.socketTextStream(&quot;localhost&quot;, 9999)</span><br><span class="line">wordcount &#x3D; lines\</span><br><span class="line">    .flatMap(lambda l: l.split())\</span><br><span class="line">    .map(lambda w: (w, 1))\</span><br><span class="line">    .reduceByKey(lambda a, b: a + b)</span><br><span class="line"></span><br><span class="line">wordcount.pprint()</span><br><span class="line"></span><br><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure>

<h4 id="使用-list-或-rdds-创建输入流-用于测试"><a href="#使用-list-或-rdds-创建输入流-用于测试" class="headerlink" title="使用 list 或 rdds 创建输入流(用于测试)"></a>使用 list 或 rdds 创建输入流(用于测试)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">from pyspark import SparkContext</span><br><span class="line">from pyspark.streaming import StreamingContext</span><br><span class="line"></span><br><span class="line">sc &#x3D; SparkContext(&quot;local[4]&quot;, &quot;streaming_rdds&quot;)</span><br><span class="line">ssc &#x3D; StreamingContext(sc, 1)</span><br><span class="line"></span><br><span class="line">queue &#x3D; []</span><br><span class="line"></span><br><span class="line">for i in range(10):</span><br><span class="line">    queue +&#x3D; [ssc.sparkContext.parallelize([j for j in range(1, 1001)], 10)]</span><br><span class="line"></span><br><span class="line">wordcount &#x3D; ssc.queueStream(queue).map(lambda x: (x % 10, 1)).reduceByKey(lambda a, b: a + b)</span><br><span class="line">wordcount.pprint()</span><br><span class="line"></span><br><span class="line">ssc.start()</span><br><span class="line">time.sleep(10)</span><br><span class="line"></span><br><span class="line"># stopGracefully, 等待所有任务完成</span><br><span class="line">ssc.stop(stopSparkContext&#x3D;True, stopGraceFully&#x3D;True)</span><br></pre></td></tr></table></figure>

<h4 id="kafka-作为数据源"><a href="#kafka-作为数据源" class="headerlink" title="kafka 作为数据源"></a>kafka 作为数据源</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">from pyspark import SparkContext</span><br><span class="line">from pyspark.streaming import StreamingContext</span><br><span class="line">from pyspark.streaming.kafka import KafkaUtils</span><br><span class="line"></span><br><span class="line">sc &#x3D; SparkContext(&quot;local[4]&quot;, &quot;streaming-kafka&quot;)</span><br><span class="line">ssc &#x3D; StreamingContext(sc, batchDuration&#x3D;3)</span><br><span class="line"></span><br><span class="line">zkQuorum &#x3D; &quot;172.17.0.2:2181&quot;</span><br><span class="line">group_id &#x3D; &quot;group-5&quot;</span><br><span class="line">topics &#x3D; &#123;</span><br><span class="line">    &quot;test&quot;: 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">kafkaStream &#x3D; KafkaUtils.createStream(ssc, zkQuorum, group_id, topics)</span><br><span class="line"></span><br><span class="line">word_counts &#x3D; kafkaStream\</span><br><span class="line">    .map(lambda x: x[1])\</span><br><span class="line">    .flatMap(lambda line: line.split(&quot; &quot;))\</span><br><span class="line">    .map(lambda word: (word, 1))\</span><br><span class="line">    .reduceByKey(lambda a, b: a + b)</span><br><span class="line"></span><br><span class="line">word_counts.pprint()</span><br><span class="line"></span><br><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure>
      
       
    </div>
</article>


<p>
    <a  class="dashang" onclick="dashangToggle()">赏</a>
</p>


<div class="article_copyright">
    <p><span class="copy-title">文章标题:</span>Spark 读取和转存数据(python)</p>
    <p><span class="copy-title">文章字数:</span><span class="post-count">2.1k</span></p>
    <p><span class="copy-title">本文作者:</span><a  title="Waterandair">Waterandair</a></p>
    <p><span class="copy-title">发布时间:</span>2018-01-01, 07:34:19</p>
    <p><span class="copy-title">最后更新:</span>2019-12-28, 14:03:59</p>
    <span class="copy-title">原始链接:</span><a class="post-url" href="/2018-01-01-pyspark-read-write.html" title="Spark 读取和转存数据(python)">https://waterandair.github.io/2018-01-01-pyspark-read-write.html</a>
    <p>
        <span class="copy-title">版权声明:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
    </p>
</div>





    




    </div>
    <div class="copyright">
        <p class="footer-entry">©2017 Waterandair</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full"><span class="min "></span></button>
<button class="post-toc-menu"><span class="post-toc-menu-icons"></span></button>
<div class="post-toc"><span class="post-toc-title">目录</span>
    <div class="post-toc-content">

    </div>
</div>
<a class="" id="rocket" ></a>

    </div>
</div>
<div class="acParent"></div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close"  onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>喜欢就点赞,疼爱就打赏</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">支付宝</label></span><span><label><input type="radio" name="pay" value="weixin">微信</label></span>
    </div>
</div>


</body>
<script src="/js/jquery.pjax.js?v=1.0.1" ></script>

<script src="/js/script.js?v=1.0.1" ></script>
<script>
    var img_resize = 'default';
    /*作者、标签的自动补全*/
    $(function () {
        $('.search').AutoComplete({
            'data': ['#时间复杂度','#大O算法','#Ansible','#大数据','#Redis','#Nosql','#Docker','#Go','#后端开发','#Linux','#Hadoop','#Hive','#环境搭建','#Java','#Kafka','#消息队列','#Zookeeper','#机器学习','#回归','#MySQL','#音乐','#Numpy','#Pandas','#Python','#Spark','#开发','#RPC','#性能调优','#原理','#Spark 原理','#工具','#分布式协作框架','#Linux 权限问题',],
            'itemHeight': 20,
            'width': 418
        }).AutoComplete('show');
    })
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $(".post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        
        $('pre code').each(function(){
            var lines = $(this).text().split('\n').length - 1, widther='';
            if (lines>99) {
                widther = 'widther'
            }
            var $numbering = $('<ul/>').addClass('pre-numbering ' + widther).attr("unselectable","on");
            $(this).addClass('has-numbering ' + widther)
                    .parent()
                    .append($numbering);
            for(var i=1;i<=lines;i++){
                $numbering.append($('<li/>').text(i));
            }
        });
        

        /*访问数量*/
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<style>
    pre{
        position: relative;
        margin-bottom: 24px;
        border-radius: 10px;
        border: 1px solid #e2dede;
        background: #FFF;
        overflow: hidden;
    }
    code.has-numbering{
        margin-left: 30px;
    }
    code.has-numbering.widther{
        margin-left: 35px;
    }
    .pre-numbering{
        margin: 0px;
        position: absolute;
        top: 0;
        left: 0;
        width: 20px;
        padding: 0.5em 3px 0.7em 5px;
        border-right: 1px solid #C3CCD0;
        text-align: right;
        color: #AAA;
        background-color: ;
    }
    .pre-numbering.widther {
        width: 35px;
    }
</style>

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
        .nav .hide-list.fullscreen {
            left: 492px
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    
    .post .pjax article .article-entry>ol, .post .pjax article .article-entry>ul, .post .pjax article>ol, .post .pjax article>ul{
        border: #e2dede solid 1px;
        border-radius: 10px;
        padding: 10px 32px 10px 56px;
    }
    .post .pjax article .article-entry li>ol, .post .pjax article .article-entry li>ul,.post .pjax article li>ol, .post .pjax article li>ul{
        padding-top: 5px;
        padding-bottom: 5px;
    }
    .post .pjax article .article-entry>ol>li, .post .pjax article .article-entry>ul>li,.post .pjax article>ol>li, .post .pjax article>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    .post .pjax article .article-entry li>ol>li, .post .pjax article .article-entry li>ul>li,.post .pjax article li>ol>li, .post .pjax article li>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    

    
    .post .pjax article :not(pre) > code {
        color: #24292e;
        font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
        background-color: rgba(27,31,35,.05);
        border-radius: 3px;
        font-size: 85%;
        margin: 0;
        padding: .2em .4em;
    }
    
</style>






<div class="mobile-menus-out" >

</div>
<div class="mobile-menus">
    
    
    
    <a class="dynamic-menu " target="_blank"  href="https://github.com/waterandair">github</a>
    
</div>


</html>
